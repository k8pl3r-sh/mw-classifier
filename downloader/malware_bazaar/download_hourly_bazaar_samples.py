import os
import requests
from bs4 import BeautifulSoup
import re
import zipfile
from typing import Optional


# TODO : faire des fonctions
# TODO : sÃ©curiser le dossier temp avec des droits de lecture uniquement + dans une VM/VPS, via cronjob/...
#  pour dockeriser

# A ajouter dans le YAML de configuration
URL = "https://datalake.abuse.ch/malware-bazaar/hourly/"
FILE_LOG = "downloaded_zip.txt"

def check_previous_download(filename: str, file_log: str) -> bool:
    """
    Check if the file has already been downloaded, return True if it has, False otherwise
    Parameters
    ----------
    filename : name of the potential file to downloader
    file_log : logs of previous downloaded files
    """
    try:
        with open(file_log, "r") as f:
            lines = f.readlines()
            for line in lines:

                if filename in line.strip():
                    print(f"Already downloaded {filename}")
                    return True

    except FileNotFoundError:
        return False


def get_hourly_samples(url: str) -> Optional[str | None]:
    # Send a GET request to the URL
    response = requests.get(url)

    # Check if the request was successful
    if response.status_code == 200:
        # Parse the HTML content
        soup = BeautifulSoup(response.content, "html.parser")

        # Find all links to zip files
        links = soup.find_all("a", href=re.compile(r'\.zip$'))

        # Extract the link of the latest zip file
        latest_zip = links[-1]['href']  # Assuming the last link is the latest

        # Construct the full URL of the latest zip file
        full_url = url + latest_zip

        # Download the zip file
        r = requests.get(full_url)
        if not check_previous_download(latest_zip, FILE_LOG):
            # Save the zip file
            with open(latest_zip, 'wb') as f:
                f.write(r.content)

            print(f"Latest zip file downloaded: {latest_zip}")

            with open(FILE_LOG, "a") as f:
                f.write(f"{latest_zip}\n")
            return latest_zip
    else:
        print("Failed to fetch data.")
        return None

def extract_zip(zip_path):
    # Create a directory to extract the contents
    directory = "temp"
    os.makedirs(directory, exist_ok=True)

    # Extract the contents of the zip file with the password "infected"
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(directory, pwd=b"infected")

    print("Zip file extracted successfully.")
    os.remove(zip_path)


if __name__ == '__main__':
    zip_path = get_hourly_samples(URL)
    if zip_path:
        extract_zip(zip_path)
