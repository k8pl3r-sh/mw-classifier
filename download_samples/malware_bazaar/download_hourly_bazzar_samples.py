import os
import requests
from bs4 import BeautifulSoup
import re
import zipfile

# TODO : check by date instead of the latest to confirm it works
# TODO : faire des fonctions
# TODO : s√©curiser le dossier temp avec des droits de lecture uniquement + dans une VM/VPS, via cronjob/...
#  pour dockeriser

# URL of the page
url = "https://datalake.abuse.ch/malware-bazaar/hourly/"

def get_hourly_samples(url):
    # Send a GET request to the URL
    response = requests.get(url)

    # Check if the request was successful
    if response.status_code == 200:
        # Parse the HTML content
        soup = BeautifulSoup(response.content, "html.parser")

        # Find all links to zip files
        links = soup.find_all("a", href=re.compile(r'\.zip$'))

        # Extract the link of the latest zip file
        latest_zip = links[-1]['href']  # Assuming the last link is the latest

        # Construct the full URL of the latest zip file
        full_url = url + latest_zip

        # Download the zip file
        r = requests.get(full_url)

        # Save the zip file
        with open(latest_zip, 'wb') as f:
            f.write(r.content)

        print(f"Latest zip file downloaded: {latest_zip}")
        return latest_zip
    else:
        print("Failed to fetch data.")
        return None

def extract_zip(zip_path):
    # Create a directory to extract the contents
    directory = "temp"
    os.makedirs(directory, exist_ok=True)

    # Extract the contents of the zip file with the password "infected"
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(directory, pwd=b"infected")

    print("Zip file extracted successfully.")
    os.remove(zip_path)


if __name__ == '__main__':
    zip_path = get_hourly_samples(url)
    extract_zip(zip_path)